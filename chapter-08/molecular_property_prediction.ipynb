{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "12de1ef1",
      "metadata": {
        "id": "12de1ef1"
      },
      "source": [
        "# Molecular Property Prediction\n",
        "\n",
        "####This exercise is part of *Chapter 8* in the book *Applied Machine Learning for Healthcare and Lifesciences on AWS*. Make sure you have completed the steps as outlined in the prerequistes section and the initial steps in the section *Building a molecular property prediction model on Sagemaker* of *Chapter 8* to successfully complete this exercise.\n",
        "\n",
        "In this exercise, we will train a molecular property prediction model on Sagemaker using a custom training container. We will run the training in two modes.\n",
        "1. **Local Mode**: In this mode, we will test our custom container by running a single model for Human Intestinal Absorption (HIA) prediction model. \n",
        "2. **Sagemaker training mode**: In this mode, we will run multiple ADME models on a GPU on Sagemaker. \n",
        "\n",
        "We will then download the trained models locally. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bd3bd0a",
      "metadata": {
        "id": "3bd3bd0a"
      },
      "source": [
        "Let's begin by building and pushing our docker container. This is done by using the docker. Let's use our example docker file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d745406a",
      "metadata": {
        "id": "d745406a",
        "outputId": "97cbf24d-840f-43bc-f66b-056ab2204767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[37m# Part of the implementation of this container is based on the Amazon SageMaker Apache MXNet container.\u001b[39;49;00m\r\n",
            "\u001b[37m# https://github.com/aws/sagemaker-mxnet-container\u001b[39;49;00m\r\n",
            "\r\n",
            "\u001b[34mFROM\u001b[39;49;00m \u001b[33mubuntu:16.04\u001b[39;49;00m\r\n",
            "\r\n",
            "\u001b[34mLABEL\u001b[39;49;00m \u001b[31mmaintainer\u001b[39;49;00m=\u001b[33m\"Amazon AI\"\u001b[39;49;00m\r\n",
            "\r\n",
            "\u001b[37m# Defining some variables used at build time to install Python3\u001b[39;49;00m\r\n",
            "\u001b[34mARG\u001b[39;49;00m \u001b[31mPYTHON\u001b[39;49;00m=python3\r\n",
            "\u001b[34mARG\u001b[39;49;00m \u001b[31mPYTHON_PIP\u001b[39;49;00m=python3-pip\r\n",
            "\u001b[34mARG\u001b[39;49;00m \u001b[31mPIP\u001b[39;49;00m=pip3\r\n",
            "\u001b[34mARG\u001b[39;49;00m \u001b[31mPYTHON_VERSION\u001b[39;49;00m=\u001b[34m3\u001b[39;49;00m.6.6\r\n",
            "\r\n",
            "\u001b[37m# Install some handful libraries like curl, wget, git, build-essential, zlib\u001b[39;49;00m\r\n",
            "\u001b[34mRUN\u001b[39;49;00m apt-get update && apt-get install -y --no-install-recommends software-properties-common && \u001b[33m\\\u001b[39;49;00m\r\n",
            "    add-apt-repository ppa:deadsnakes/ppa -y && \u001b[33m\\\u001b[39;49;00m\r\n",
            "    apt-get update && apt-get install -y --no-install-recommends \u001b[33m\\\u001b[39;49;00m\r\n",
            "        build-essential \u001b[33m\\\u001b[39;49;00m\r\n",
            "        ca-certificates \u001b[33m\\\u001b[39;49;00m\r\n",
            "        curl \u001b[33m\\\u001b[39;49;00m\r\n",
            "        wget \u001b[33m\\\u001b[39;49;00m\r\n",
            "        git \u001b[33m\\\u001b[39;49;00m\r\n",
            "        libopencv-dev \u001b[33m\\\u001b[39;49;00m\r\n",
            "        openssh-client \u001b[33m\\\u001b[39;49;00m\r\n",
            "        openssh-server \u001b[33m\\\u001b[39;49;00m\r\n",
            "        vim \u001b[33m\\\u001b[39;49;00m\r\n",
            "        zlib1g-dev && \u001b[33m\\\u001b[39;49;00m\r\n",
            "    rm -rf /var/lib/apt/lists/*\r\n",
            "\r\n",
            "\u001b[37m# Installing Python3\u001b[39;49;00m\r\n",
            "\u001b[34mRUN\u001b[39;49;00m wget https://www.python.org/ftp/python/\u001b[31m$PYTHON_VERSION\u001b[39;49;00m/Python-\u001b[31m$PYTHON_VERSION\u001b[39;49;00m.tgz && \u001b[33m\\\u001b[39;49;00m\r\n",
            "        tar -xvf Python-\u001b[31m$PYTHON_VERSION\u001b[39;49;00m.tgz && \u001b[36mcd\u001b[39;49;00m Python-\u001b[31m$PYTHON_VERSION\u001b[39;49;00m && \u001b[33m\\\u001b[39;49;00m\r\n",
            "        ./configure && make && make install && \u001b[33m\\\u001b[39;49;00m\r\n",
            "        apt-get update && apt-get install -y --no-install-recommends libreadline-gplv2-dev libncursesw5-dev libssl-dev libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev && \u001b[33m\\\u001b[39;49;00m\r\n",
            "        make && make install && rm -rf ../Python-\u001b[31m$PYTHON_VERSION\u001b[39;49;00m* && \u001b[33m\\\u001b[39;49;00m\r\n",
            "        ln -s /usr/local/bin/pip3 /usr/bin/pip\r\n",
            "\r\n",
            "\u001b[37m# Upgrading pip and creating symbolic link for python3\u001b[39;49;00m\r\n",
            "\u001b[34mRUN\u001b[39;49;00m \u001b[33m${\u001b[39;49;00m\u001b[31mPIP\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m --no-cache-dir install --upgrade pip\r\n",
            "\u001b[34mRUN\u001b[39;49;00m ln -s \u001b[34m$(\u001b[39;49;00mwhich \u001b[33m${\u001b[39;49;00m\u001b[31mPYTHON\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[34m)\u001b[39;49;00m /usr/local/bin/python\r\n",
            "\r\n",
            "\u001b[34mWORKDIR\u001b[39;49;00m\u001b[33m /\u001b[39;49;00m\r\n",
            "\r\n",
            "\u001b[37m# Installing numpy, pandas, scikit-learn, scipy\u001b[39;49;00m\r\n",
            "\u001b[34mRUN\u001b[39;49;00m \u001b[33m${\u001b[39;49;00m\u001b[31mPIP\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m install --no-cache --upgrade \u001b[33m\\\u001b[39;49;00m\r\n",
            "        \u001b[31mnumpy\u001b[39;49;00m==\u001b[34m1\u001b[39;49;00m.14.5 \u001b[33m\\\u001b[39;49;00m\r\n",
            "        \u001b[31mpandas\u001b[39;49;00m==\u001b[34m0\u001b[39;49;00m.24.1 \u001b[33m\\\u001b[39;49;00m\r\n",
            "        scikit-learn==\u001b[34m0\u001b[39;49;00m.20.3 \u001b[33m\\\u001b[39;49;00m\r\n",
            "        \u001b[31mrequests\u001b[39;49;00m==\u001b[34m2\u001b[39;49;00m.21.0 \u001b[33m\\\u001b[39;49;00m\r\n",
            "        \u001b[31mscipy\u001b[39;49;00m==\u001b[34m1\u001b[39;49;00m.2.2\r\n",
            "\r\n",
            "\u001b[37m# Setting some environment variables.\u001b[39;49;00m\r\n",
            "\u001b[34mENV\u001b[39;49;00m \u001b[31mPYTHONDONTWRITEBYTECODE\u001b[39;49;00m=\u001b[34m1\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "    \u001b[31mPYTHONUNBUFFERED\u001b[39;49;00m=\u001b[34m1\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "    \u001b[31mLD_LIBRARY_PATH\u001b[39;49;00m=\u001b[33m\"\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mLD_LIBRARY_PATH\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m:/usr/local/lib\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\r\n",
            "    \u001b[31mPYTHONIOENCODING\u001b[39;49;00m=UTF-8 \u001b[33m\\\u001b[39;49;00m\r\n",
            "    \u001b[31mLANG\u001b[39;49;00m=C.UTF-8 \u001b[33m\\\u001b[39;49;00m\r\n",
            "    \u001b[31mLC_ALL\u001b[39;49;00m=C.UTF-8\r\n",
            "\r\n",
            "\u001b[34mRUN\u001b[39;49;00m \u001b[33m${\u001b[39;49;00m\u001b[31mPIP\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m install --no-cache --upgrade \u001b[33m\\\u001b[39;49;00m\r\n",
            "    sagemaker-training\r\n",
            "\r\n",
            "\r\n",
            "\u001b[34mRUN\u001b[39;49;00m pip install rdkit-pypi\r\n",
            "\u001b[34mRUN\u001b[39;49;00m pip install PyTDC\r\n",
            "\u001b[34mRUN\u001b[39;49;00m pip install pandas-flavor\r\n",
            "\u001b[34mRUN\u001b[39;49;00m pip install git+https://github.com/bp-kelley/descriptastorus\r\n",
            "\u001b[34mRUN\u001b[39;49;00m pip install DeepPurpose\r\n",
            "\u001b[34mRUN\u001b[39;49;00m pip install pytest-shutil\r\n",
            "\u001b[34mRUN\u001b[39;49;00m pip install boto3\r\n",
            "\r\n",
            "\u001b[37m# Copies code under /opt/ml/code where sagemaker-containers expects to find the script to run\u001b[39;49;00m\r\n",
            "\u001b[34mCOPY\u001b[39;49;00m train_local.py /opt/ml/code/train_local.py\r\n",
            "\u001b[34mCOPY\u001b[39;49;00m train_sm.py /opt/ml/code/train_sm.py\r\n"
          ]
        }
      ],
      "source": [
        "!pygmentize Dockerfile"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38591fbf",
      "metadata": {
        "id": "38591fbf"
      },
      "source": [
        "We use a base `ubuntu:16.04` container. We then install our necessary base software and then add some custom libraries like `RDKit` and `DeepPurpose`. Finally, we copy our training scripts to the location `//opt/ml/code/`. This is the location where Sagemaker picks up the training code from.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Let's now look at our local training script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79f07008",
      "metadata": {
        "id": "79f07008",
        "outputId": "c1ebe0e7-58d8-404b-95ea-6161f5ea3c30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[37m# Portions of this script is borrowed from https://github.com/mims-harvard/TDC/blob/main/tutorials/TDC_104_ML_Model_DeepPurpose.ipynb\u001b[39;49;00m\r\n",
            "\r\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mDeepPurpose\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m utils, CompoundPred\r\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtdc\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msingle_pred\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ADME\r\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mwarnings\u001b[39;49;00m\r\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
            "warnings.filterwarnings(\u001b[33m\"\u001b[39;49;00m\u001b[33mignore\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
            "\r\n",
            "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\r\n",
            "    \r\n",
            "    \r\n",
            "    parser = argparse.ArgumentParser()\r\n",
            "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
            "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
            "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--sagemaker_program\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSAGEMAKER_PROGRAM\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
            "    args = parser.parse_args()\r\n",
            "\r\n",
            "    X, y = ADME(name = \u001b[33m'\u001b[39;49;00m\u001b[33mHIA_Hou\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).get_data(\u001b[36mformat\u001b[39;49;00m = \u001b[33m'\u001b[39;49;00m\u001b[33mDeepPurpose\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
            "    drug_encoding = \u001b[33m'\u001b[39;49;00m\u001b[33mMPNN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
            "    train, val, test = utils.data_process(X_drug = X, \r\n",
            "                                      y = y, \r\n",
            "                                      drug_encoding = drug_encoding,\r\n",
            "                                      random_seed = \u001b[33m'\u001b[39;49;00m\u001b[33mTDC\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
            "    config = utils.generate_config(drug_encoding = drug_encoding, \r\n",
            "                         train_epoch = \u001b[34m1\u001b[39;49;00m, \r\n",
            "                         LR = \u001b[34m0.001\u001b[39;49;00m, \r\n",
            "                         batch_size = \u001b[34m128\u001b[39;49;00m,\r\n",
            "                         mpnn_hidden_size = \u001b[34m32\u001b[39;49;00m,\r\n",
            "                         mpnn_depth = \u001b[34m2\u001b[39;49;00m\r\n",
            "                        )\r\n",
            "    model = CompoundPred.model_initialize(**config)\r\n",
            "    model.train(train, val, test)\r\n",
            "    \r\n",
            "    model.save_model(args.model_dir)\r\n"
          ]
        }
      ],
      "source": [
        "!pygmentize train_local.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47f123a7",
      "metadata": {
        "id": "47f123a7"
      },
      "source": [
        "This is a script that we run locally to test our training container. It runs a single model for HIA prediction. Note that we pass the hyperparameter `sagemaker_program` to make sure Sagemaker is picking the correct script to run.\n",
        "\n",
        "\n",
        "Let's now look at the script for Sagemaker training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f0f4fef",
      "metadata": {
        "id": "5f0f4fef",
        "outputId": "e0fa7890-22a2-4382-9a2a-ebfa431f2576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[37m# Portions of this script is borrowed from https://github.com/mims-harvard/TDC/blob/main/tutorials/TDC_104_ML_Model_DeepPurpose.ipynb\u001b[39;49;00m\r\n",
            "\r\n",
            "\r\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtdc\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m retrieve_dataset_names\r\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtdc\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msingle_pred\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ADME\r\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mDeepPurpose\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m utils, CompoundPred\r\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mwarnings\u001b[39;49;00m\r\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mshutil\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m make_archive\r\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mboto3\u001b[39;49;00m\r\n",
            "warnings.filterwarnings(\u001b[33m\"\u001b[39;49;00m\u001b[33mignore\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
            "\r\n",
            "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\r\n",
            "    \r\n",
            "    \r\n",
            "    parser = argparse.ArgumentParser()\r\n",
            "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
            "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
            "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--sagemaker_program\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSAGEMAKER_PROGRAM\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
            "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--models_output_bucket\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\r\n",
            "    args = parser.parse_args()\r\n",
            "    \r\n",
            "    \u001b[37m# Check whether the specified path exists or not\u001b[39;49;00m\r\n",
            "    isExist = os.path.exists(\u001b[33m'\u001b[39;49;00m\u001b[33m./models\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
            "\r\n",
            "    \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m isExist:\r\n",
            "\r\n",
            "      \u001b[37m# Create a new directory because it does not exist \u001b[39;49;00m\r\n",
            "      os.makedirs(\u001b[33m'\u001b[39;49;00m\u001b[33m./models\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
            "      \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mThe new directory is created!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
            "    \r\n",
            "    \r\n",
            "    bucket_name=args.models_output_bucket\r\n",
            "    adme_datasets = retrieve_dataset_names(\u001b[33m'\u001b[39;49;00m\u001b[33mADME\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)   \r\n",
            "    \u001b[34mfor\u001b[39;49;00m dataset_name \u001b[35min\u001b[39;49;00m adme_datasets:\r\n",
            "        X, y = ADME(name = dataset_name).get_data(\u001b[36mformat\u001b[39;49;00m = \u001b[33m'\u001b[39;49;00m\u001b[33mDeepPurpose\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
            "        drug_encoding = \u001b[33m'\u001b[39;49;00m\u001b[33mMorgan\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
            "        train, val, test = utils.data_process(X_drug = X, \r\n",
            "                                          y = y, \r\n",
            "                                          drug_encoding = drug_encoding,\r\n",
            "                                          random_seed = \u001b[33m'\u001b[39;49;00m\u001b[33mTDC\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
            "        config = utils.generate_config(drug_encoding = drug_encoding, \r\n",
            "                             train_epoch = \u001b[34m5\u001b[39;49;00m, \r\n",
            "                             LR = \u001b[34m0.001\u001b[39;49;00m, \r\n",
            "                             batch_size = \u001b[34m128\u001b[39;49;00m,\r\n",
            "                             mpnn_hidden_size = \u001b[34m32\u001b[39;49;00m,\r\n",
            "                             mpnn_depth = \u001b[34m2\u001b[39;49;00m\r\n",
            "                            )\r\n",
            "        model = CompoundPred.model_initialize(**config)\r\n",
            "        model.train(train, val, test)\r\n",
            "        model.save_model(\u001b[33m'\u001b[39;49;00m\u001b[33m./models/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + dataset_name + \u001b[33m'\u001b[39;49;00m\u001b[33m_model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
            "        res = os.listdir(\u001b[33m'\u001b[39;49;00m\u001b[33m./models/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
            "        \u001b[36mprint\u001b[39;49;00m(res)\r\n",
            "\r\n",
            "    res1 = os.listdir(\u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
            "    \u001b[36mprint\u001b[39;49;00m(res1)\r\n",
            "    make_archive(\u001b[33m'\u001b[39;49;00m\u001b[33m./models\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mzip\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, root_dir=\u001b[33m'\u001b[39;49;00m\u001b[33m./models\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
            "\r\n",
            "    s3 = boto3.client(\u001b[33m\"\u001b[39;49;00m\u001b[33ms3\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
            "    s3.upload_file(\u001b[33m'\u001b[39;49;00m\u001b[33mmodels.zip\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, bucket_name, \u001b[33m'\u001b[39;49;00m\u001b[33mADME/models/models.zip\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n"
          ]
        }
      ],
      "source": [
        "!pygmentize train_sm.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04013bf8",
      "metadata": {
        "id": "04013bf8"
      },
      "source": [
        "This script also accepts an S3 output location for our trained model. This script trains multiple ADME models in a loop and uploads them to an output location on S3. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30723aa3",
      "metadata": {
        "id": "30723aa3"
      },
      "source": [
        "Let's now build and push the container using the following shell script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c218aa2",
      "metadata": {
        "id": "7c218aa2",
        "outputId": "1aae598d-e82d-4569-e77e-a70c8e4e1f4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "485822383573\n",
            "Login Succeeded\n",
            "\r\n",
            "Step 1/23 : FROM ubuntu:16.04\n",
            " ---> b6f507652425\n",
            "Step 2/23 : LABEL maintainer=\"Amazon AI\"\n",
            " ---> Using cache\n",
            " ---> 7d3810176a2e\n",
            "Step 3/23 : ARG PYTHON=python3\n",
            " ---> Using cache\n",
            " ---> 683c419be179\n",
            "Step 4/23 : ARG PYTHON_PIP=python3-pip\n",
            " ---> Using cache\n",
            " ---> b8624329a0e4\n",
            "Step 5/23 : ARG PIP=pip3\n",
            " ---> Using cache\n",
            " ---> a42942582dae\n",
            "Step 6/23 : ARG PYTHON_VERSION=3.6.6\n",
            " ---> Using cache\n",
            " ---> 1a0cabeefc40\n",
            "Step 7/23 : RUN apt-get update && apt-get install -y --no-install-recommends software-properties-common &&     add-apt-repository ppa:deadsnakes/ppa -y &&     apt-get update && apt-get install -y --no-install-recommends         build-essential         ca-certificates         curl         wget         git         libopencv-dev         openssh-client         openssh-server         vim         zlib1g-dev &&     rm -rf /var/lib/apt/lists/*\n",
            " ---> Using cache\n",
            " ---> 0ea7cc8cd8de\n",
            "Step 8/23 : RUN wget https://www.python.org/ftp/python/$PYTHON_VERSION/Python-$PYTHON_VERSION.tgz &&         tar -xvf Python-$PYTHON_VERSION.tgz && cd Python-$PYTHON_VERSION &&         ./configure && make && make install &&         apt-get update && apt-get install -y --no-install-recommends libreadline-gplv2-dev libncursesw5-dev libssl-dev libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev &&         make && make install && rm -rf ../Python-$PYTHON_VERSION* &&         ln -s /usr/local/bin/pip3 /usr/bin/pip\n",
            " ---> Using cache\n",
            " ---> b450e47d8d2d\n",
            "Step 9/23 : RUN ${PIP} --no-cache-dir install --upgrade pip\n",
            " ---> Using cache\n",
            " ---> b0a2025ce6a2\n",
            "Step 10/23 : RUN ln -s $(which ${PYTHON}) /usr/local/bin/python\n",
            " ---> Using cache\n",
            " ---> 9c4fad68a881\n",
            "Step 11/23 : WORKDIR /\n",
            " ---> Using cache\n",
            " ---> 070aa53b9089\n",
            "Step 12/23 : RUN ${PIP} install --no-cache --upgrade         numpy==1.14.5         pandas==0.24.1         scikit-learn==0.20.3         requests==2.21.0         scipy==1.2.2\n",
            " ---> Using cache\n",
            " ---> 91a41f03098f\n",
            "Step 13/23 : ENV PYTHONDONTWRITEBYTECODE=1     PYTHONUNBUFFERED=1     LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:/usr/local/lib\"     PYTHONIOENCODING=UTF-8     LANG=C.UTF-8     LC_ALL=C.UTF-8\n",
            " ---> Using cache\n",
            " ---> fbeb9c5dc1db\n",
            "Step 14/23 : RUN ${PIP} install --no-cache --upgrade     sagemaker-training\n",
            " ---> Using cache\n",
            " ---> 2d16ebb44773\n",
            "Step 15/23 : RUN pip install rdkit-pypi\n",
            " ---> Using cache\n",
            " ---> 18c273648289\n",
            "Step 16/23 : RUN pip install PyTDC\n",
            " ---> Using cache\n",
            " ---> f1e3c3f4a451\n",
            "Step 17/23 : RUN pip install pandas-flavor\n",
            " ---> Using cache\n",
            " ---> 8ada73586f01\n",
            "Step 18/23 : RUN pip install git+https://github.com/bp-kelley/descriptastorus\n",
            " ---> Using cache\n",
            " ---> 824e428ab888\n",
            "Step 19/23 : RUN pip install DeepPurpose\n",
            " ---> Using cache\n",
            " ---> 833a704dfe46\n",
            "Step 20/23 : RUN pip install pytest-shutil\n",
            " ---> Using cache\n",
            " ---> afd393d6eb1c\n",
            "Step 21/23 : RUN pip install boto3\n",
            " ---> Using cache\n",
            " ---> 17e819f2f4b9\n",
            "Step 22/23 : COPY train_local.py /opt/ml/code/train_local.py\n",
            " ---> 5cd131e1b518\n",
            "Step 23/23 : COPY train_sm.py /opt/ml/code/train_sm.py\n",
            " ---> 5648427ed98c\n",
            "Successfully built 5648427ed98c\n",
            "Successfully tagged sagemaker-deeppurpose:latest\n",
            "The push refers to repository [485822383573.dkr.ecr.us-east-1.amazonaws.com/sagemaker-deeppurpose]\n",
            "8eca290ac769: Preparing\n",
            "d29511a5ed9e: Preparing\n",
            "10b908113b81: Preparing\n",
            "f39efaeee0bc: Preparing\n",
            "5b8b92537490: Preparing\n",
            "3f28340b79bf: Preparing\n",
            "ab7aa6aea974: Preparing\n",
            "e5b8e6147aa8: Preparing\n",
            "e402ab955752: Preparing\n",
            "7b86cdf37e7d: Preparing\n",
            "a8921e0e27bf: Preparing\n",
            "4fe9a064275d: Preparing\n",
            "908ed4810566: Preparing\n",
            "ead85a8639fc: Preparing\n",
            "ddc7b974cfa7: Preparing\n",
            "1251204ef8fc: Preparing\n",
            "47ef83afae74: Preparing\n",
            "df54c846128d: Preparing\n",
            "be96a3f634de: Preparing\n",
            "e5b8e6147aa8: Waiting\n",
            "e402ab955752: Waiting\n",
            "7b86cdf37e7d: Waiting\n",
            "a8921e0e27bf: Waiting\n",
            "3f28340b79bf: Waiting\n",
            "4fe9a064275d: Waiting\n",
            "908ed4810566: Waiting\n",
            "ead85a8639fc: Waiting\n",
            "df54c846128d: Waiting\n",
            "ddc7b974cfa7: Waiting\n",
            "1251204ef8fc: Waiting\n",
            "47ef83afae74: Waiting\n",
            "be96a3f634de: Waiting\n",
            "ab7aa6aea974: Waiting\n",
            "d29511a5ed9e: Pushed\n",
            "8eca290ac769: Pushed\n",
            "10b908113b81: Pushed\n",
            "3f28340b79bf: Pushed\n",
            "f39efaeee0bc: Pushed\n",
            "e5b8e6147aa8: Pushed\n",
            "ab7aa6aea974: Pushed\n",
            "4fe9a064275d: Pushed\n",
            "7b86cdf37e7d: Pushed\n",
            "908ed4810566: Pushed\n",
            "e402ab955752: Pushed\n",
            "1251204ef8fc: Pushed\n",
            "47ef83afae74: Pushed\n",
            "df54c846128d: Pushed\n",
            "a8921e0e27bf: Pushed\n",
            "be96a3f634de: Pushed\n",
            "ead85a8639fc: Pushed\n",
            "ddc7b974cfa7: Pushed\n",
            "5b8b92537490: Pushed\n",
            "latest: digest: sha256:9c94068256a66cdd08f96b4ab1e21074f1ba95f2e9231d076ae1a011e15e98b4 size: 4308\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
            "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
            "Configure a credential helper to remove this warning. See\n",
            "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%sh\n",
        "\n",
        "docker_name=sagemaker-deeppurpose\n",
        "account=$(aws sts get-caller-identity --query Account --output text)\n",
        "echo $account\n",
        "region=$(aws configure get region)\n",
        "\n",
        "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${docker_name}:latest\"\n",
        "# If the repository doesn't exist in ECR, create it.\n",
        "aws ecr describe-repositories --repository-names \"${docker_name}\" > /dev/null 2>&1\n",
        "if [ $? -ne 0 ]\n",
        "then\n",
        "    aws ecr create-repository --repository-name \"${docker_name}\" > /dev/null\n",
        "fi\n",
        "\n",
        "# Get the login command from ECR and execute it directly\n",
        "$(aws ecr get-login --region ${region} --no-include-email)\n",
        "docker build -t $docker_name -f Dockerfile .\n",
        "docker tag ${docker_name} ${fullname}\n",
        "docker push ${fullname}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32ba2125",
      "metadata": {
        "id": "32ba2125"
      },
      "source": [
        "Now that we have the container, we will use it to train. Let's first import some required libraries and designate the default S3 bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33046cb7",
      "metadata": {
        "id": "33046cb7"
      },
      "outputs": [],
      "source": [
        "import sagemaker\n",
        "from sagemaker import get_execution_role\n",
        "from sagemaker.session import Session\n",
        "from sagemaker.local import LocalSession\n",
        "import boto3\n",
        "\n",
        "# Setup session\n",
        "sess = sagemaker.Session()\n",
        "bucket = sess.default_bucket()\n",
        "role = get_execution_role()\n",
        "sagemaker_session = LocalSession()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39c1ed8b",
      "metadata": {
        "id": "39c1ed8b"
      },
      "source": [
        "We will now create an estimator using our custom container. We define the local training script as the hyperparameter for this estimator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe47be9f",
      "metadata": {
        "id": "fe47be9f",
        "outputId": "beee9d2c-2a32-40cb-f284-64b302593e34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "485822383573.dkr.ecr.us-east-1.amazonaws.com/sagemaker-deeppurpose:latest\n"
          ]
        }
      ],
      "source": [
        "docker_name = \"sagemaker-deeppurpose\"\n",
        "\n",
        "\n",
        "account = sess.boto_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
        "region = sess.boto_session.region_name\n",
        "image = \"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(account, region, docker_name)\n",
        "print(image)\n",
        "task_tags = [{\"Key\": \"ML Task\", \"Value\": \"deeppurpose\"}]\n",
        "estimator = sagemaker.estimator.Estimator(\n",
        "    image,\n",
        "    role,\n",
        "    instance_count=1,\n",
        "    instance_type=\"local\",\n",
        "    tags=task_tags,\n",
        "    sagemaker_session=sagemaker_session,\n",
        "    hyperparameters={\"sagemaker_program\": \"train_local.py\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78ac2498",
      "metadata": {
        "id": "78ac2498"
      },
      "source": [
        "Next, let's train our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d06dd54",
      "metadata": {
        "id": "4d06dd54",
        "outputId": "aecb41a8-dd30-43ee-9927-320086a43c54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating g0rsc63n6p-algo-1-e6soy ... \n",
            "Creating g0rsc63n6p-algo-1-e6soy ... done\n",
            "Attaching to g0rsc63n6p-algo-1-e6soy\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m /usr/local/lib/python3.6/site-packages/paramiko/transport.py:33: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m   from cryptography.hazmat.backends import default_backend\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m 2022-07-29 01:02:49,120 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m 2022-07-29 01:02:49,121 sagemaker-training-toolkit INFO     Failed to parse hyperparameter sagemaker_program value train_local.py to Json.\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m Returning the value itself\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m 2022-07-29 01:02:49,134 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m 2022-07-29 01:02:49,141 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m 2022-07-29 01:02:49,141 sagemaker-training-toolkit INFO     Failed to parse hyperparameter sagemaker_program value train_local.py to Json.\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m Returning the value itself\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m 2022-07-29 01:02:49,154 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m 2022-07-29 01:02:49,157 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m 2022-07-29 01:02:49,157 sagemaker-training-toolkit INFO     Failed to parse hyperparameter sagemaker_program value train_local.py to Json.\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m Returning the value itself\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m 2022-07-29 01:02:49,170 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m 2022-07-29 01:02:49,171 sagemaker-training-toolkit INFO     Invoking user script\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m \n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m Training Env:\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m \n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m {\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"additional_framework_parameters\": {},\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"channel_input_dirs\": {},\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"current_host\": \"algo-1-e6soy\",\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"current_instance_group\": \"homogeneousCluster\",\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"current_instance_group_hosts\": [],\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"current_instance_type\": \"local\",\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"distribution_hosts\": [\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m         \"algo-1-e6soy\"\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     ],\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"distribution_instance_groups\": [],\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"framework_module\": null,\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"hosts\": [\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m         \"algo-1-e6soy\"\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     ],\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"hyperparameters\": {},\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"input_data_config\": {},\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"instance_groups\": [],\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"instance_groups_dict\": {},\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"is_hetero\": false,\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"is_master\": true,\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"is_modelparallel_enabled\": null,\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"job_name\": \"sagemaker-deeppurpose-2022-07-29-01-02-45-761\",\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"log_level\": 20,\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"master_hostname\": \"algo-1-e6soy\",\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"module_dir\": \"/opt/ml/code\",\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"module_name\": \"train_local\",\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"num_cpus\": 4,\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"num_gpus\": 0,\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"resource_config\": {\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m         \"current_host\": \"algo-1-e6soy\",\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m         \"hosts\": [\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m             \"algo-1-e6soy\"\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m         ]\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     },\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m     \"user_entry_point\": \"train_local.py\"\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m }\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m \n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m Environment variables:\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m \n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_HOSTS=[\"algo-1-e6soy\"]\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_HPS={}\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_USER_ENTRY_POINT=train_local.py\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-e6soy\",\"hosts\":[\"algo-1-e6soy\"]}\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_CHANNELS=[]\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_CURRENT_HOST=algo-1-e6soy\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_CURRENT_INSTANCE_TYPE=local\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_CURRENT_INSTANCE_GROUP_HOSTS=[]\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_INSTANCE_GROUPS=[]\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_INSTANCE_GROUPS_DICT={}\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_IS_HETERO=false\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_MODULE_NAME=train_local\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_LOG_LEVEL=20\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_FRAMEWORK_MODULE=\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_NUM_CPUS=4\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_NUM_GPUS=0\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1-e6soy\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[],\"current_instance_type\":\"local\",\"distribution_hosts\":[\"algo-1-e6soy\"],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1-e6soy\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[],\"instance_groups_dict\":{},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"sagemaker-deeppurpose-2022-07-29-01-02-45-761\",\"log_level\":20,\"master_hostname\":\"algo-1-e6soy\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train_local\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-e6soy\",\"hosts\":[\"algo-1-e6soy\"]},\"user_entry_point\":\"train_local.py\"}\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_USER_ARGS=[]\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m \n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m Invoking script with the following command:\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m \n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m /usr/local/bin/python3.6 train_local.py\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m \n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m \n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m WARNING:root:No normalization for BCUT2D_MWHI\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m WARNING:root:No normalization for BCUT2D_MWLOW\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m WARNING:root:No normalization for BCUT2D_CHGHI\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m WARNING:root:No normalization for BCUT2D_CHGLO\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m WARNING:root:No normalization for BCUT2D_LOGPHI\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m WARNING:root:No normalization for BCUT2D_MRHI\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m WARNING:root:No normalization for BCUT2D_MRLOW\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m Downloading...\n",
            "100% 40.1k/40.1k [00:00<00:00, 1.09MiB/s]\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m Loading...\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m Done!\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m Drug Property Prediction Mode...\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m in total: 578 drugs\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m encoding drug...\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m unique drugs: 578\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m Done.\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m Let's use CPU/s!\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m --- Data Preparation ---\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m --- Go for Training ---\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m Training at Epoch 1 iteration 0 with loss 0.68279. Total time 0.0 hours\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m Validation at Epoch 1 , AUROC: 0.56862 , AUPRC: 0.88669 , F1: 0.93577\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m --- Go for Testing ---\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m Testing AUROC: 0.4778877887788779 , AUPRC: 0.8781780203169165 , F1: 0.9308755760368664\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m --- Training Finished ---\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy |\u001b[0m 2022-07-29 01:02:56,324 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
            "\u001b[36mg0rsc63n6p-algo-1-e6soy exited with code 0\n",
            "\u001b[0mAborting on container exit...\n",
            "===== Job Complete =====\n"
          ]
        }
      ],
      "source": [
        "estimator.fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d554b71",
      "metadata": {
        "id": "5d554b71"
      },
      "source": [
        "Now that we have verified that the training works, we will use this container to train multiple ADME models. This time, we will define the script file to be the Sagemaker script `train_sm.py` and we also provide an output bucket where we will upload the trained models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f172b718",
      "metadata": {
        "id": "f172b718"
      },
      "outputs": [],
      "source": [
        "from sagemaker.local import LocalSession\n",
        "sagemaker_session = LocalSession()\n",
        "estimator = sagemaker.estimator.Estimator(\n",
        "    image,\n",
        "    role,\n",
        "    instance_count=1,\n",
        "    instance_type=\"ml.p2.xlarge\",\n",
        "    tags=task_tags,\n",
        "    sagemaker_session=sess,\n",
        "    hyperparameters={\"sagemaker_program\": \"train_sm.py\", \"models_output_bucket\": bucket }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35d786cd",
      "metadata": {
        "id": "35d786cd"
      },
      "source": [
        "Let's train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d33afbb7",
      "metadata": {
        "id": "d33afbb7",
        "outputId": "d1585bed-7b37-47cd-a807-b82853a6ac2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-07-29 01:03:25 Starting - Starting the training job...\n",
            "2022-07-29 01:03:50 Starting - Preparing the instances for trainingProfilerReport-1659056605: InProgress\n",
            ".........\n",
            "2022-07-29 01:05:21 Downloading - Downloading input data......\n",
            "2022-07-29 01:06:07 Training - Downloading the training image........\u001b[34m/usr/local/lib/python3.6/site-packages/paramiko/transport.py:33: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.\n",
            "  from cryptography.hazmat.backends import default_backend\u001b[0m\n",
            "\u001b[34m2022-07-29 01:07:37,608 sagemaker-training-toolkit INFO     Failed to parse hyperparameter models_output_bucket value sagemaker-us-east-1-485822383573 to Json.\u001b[0m\n",
            "\u001b[34mReturning the value itself\u001b[0m\n",
            "\u001b[34m2022-07-29 01:07:37,609 sagemaker-training-toolkit INFO     Failed to parse hyperparameter sagemaker_program value train_sm.py to Json.\u001b[0m\n",
            "\u001b[34mReturning the value itself\u001b[0m\n",
            "\u001b[34m2022-07-29 01:07:37,648 sagemaker-training-toolkit INFO     Failed to parse hyperparameter models_output_bucket value sagemaker-us-east-1-485822383573 to Json.\u001b[0m\n",
            "\u001b[34mReturning the value itself\u001b[0m\n",
            "\u001b[34m2022-07-29 01:07:37,648 sagemaker-training-toolkit INFO     Failed to parse hyperparameter sagemaker_program value train_sm.py to Json.\u001b[0m\n",
            "\u001b[34mReturning the value itself\u001b[0m\n",
            "\u001b[34m2022-07-29 01:07:37,682 sagemaker-training-toolkit INFO     Failed to parse hyperparameter models_output_bucket value sagemaker-us-east-1-485822383573 to Json.\u001b[0m\n",
            "\u001b[34mReturning the value itself\u001b[0m\n",
            "\u001b[34m2022-07-29 01:07:37,682 sagemaker-training-toolkit INFO     Failed to parse hyperparameter sagemaker_program value train_sm.py to Json.\u001b[0m\n",
            "\u001b[34mReturning the value itself\u001b[0m\n",
            "\u001b[34m2022-07-29 01:07:37,695 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
            "\u001b[34mTraining Env:\u001b[0m\n",
            "\u001b[34m{\n",
            "    \"additional_framework_parameters\": {},\n",
            "    \"channel_input_dirs\": {},\n",
            "    \"current_host\": \"algo-1\",\n",
            "    \"current_instance_group\": \"homogeneousCluster\",\n",
            "    \"current_instance_group_hosts\": [\n",
            "        \"algo-1\"\n",
            "    ],\n",
            "    \"current_instance_type\": \"ml.p2.xlarge\",\n",
            "    \"distribution_hosts\": [],\n",
            "    \"distribution_instance_groups\": [],\n",
            "    \"framework_module\": null,\n",
            "    \"hosts\": [\n",
            "        \"algo-1\"\n",
            "    ],\n",
            "    \"hyperparameters\": {\n",
            "        \"models_output_bucket\": \"sagemaker-us-east-1-485822383573\"\n",
            "    },\n",
            "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
            "    \"input_data_config\": {},\n",
            "    \"input_dir\": \"/opt/ml/input\",\n",
            "    \"instance_groups\": [\n",
            "        \"homogeneousCluster\"\n",
            "    ],\n",
            "    \"instance_groups_dict\": {\n",
            "        \"homogeneousCluster\": {\n",
            "            \"instance_group_name\": \"homogeneousCluster\",\n",
            "            \"instance_type\": \"ml.p2.xlarge\",\n",
            "            \"hosts\": [\n",
            "                \"algo-1\"\n",
            "            ]\n",
            "        }\n",
            "    },\n",
            "    \"is_hetero\": false,\n",
            "    \"is_master\": true,\n",
            "    \"is_modelparallel_enabled\": null,\n",
            "    \"job_name\": \"sagemaker-deeppurpose-2022-07-29-01-03-25-196\",\n",
            "    \"log_level\": 20,\n",
            "    \"master_hostname\": \"algo-1\",\n",
            "    \"model_dir\": \"/opt/ml/model\",\n",
            "    \"module_dir\": \"/opt/ml/code\",\n",
            "    \"module_name\": \"train_sm\",\n",
            "    \"network_interface_name\": \"eth0\",\n",
            "    \"num_cpus\": 4,\n",
            "    \"num_gpus\": 1,\n",
            "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
            "    \"output_dir\": \"/opt/ml/output\",\n",
            "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
            "    \"resource_config\": {\n",
            "        \"current_host\": \"algo-1\",\n",
            "        \"current_instance_type\": \"ml.p2.xlarge\",\n",
            "        \"current_group_name\": \"homogeneousCluster\",\n",
            "        \"hosts\": [\n",
            "            \"algo-1\"\n",
            "        ],\n",
            "        \"instance_groups\": [\n",
            "            {\n",
            "                \"instance_group_name\": \"homogeneousCluster\",\n",
            "                \"instance_type\": \"ml.p2.xlarge\",\n",
            "                \"hosts\": [\n",
            "                    \"algo-1\"\n",
            "                ]\n",
            "            }\n",
            "        ],\n",
            "        \"network_interface_name\": \"eth0\"\n",
            "    },\n",
            "    \"user_entry_point\": \"train_sm.py\"\u001b[0m\n",
            "\u001b[34m}\u001b[0m\n",
            "\u001b[34mEnvironment variables:\u001b[0m\n",
            "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
            "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
            "\u001b[34mSM_HPS={\"models_output_bucket\":\"sagemaker-us-east-1-485822383573\"}\u001b[0m\n",
            "\u001b[34mSM_USER_ENTRY_POINT=train_sm.py\u001b[0m\n",
            "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
            "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p2.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
            "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
            "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
            "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
            "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
            "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p2.xlarge\u001b[0m\n",
            "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
            "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
            "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
            "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}}\u001b[0m\n",
            "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
            "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
            "\u001b[34mSM_MODULE_NAME=train_sm\u001b[0m\n",
            "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
            "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
            "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
            "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
            "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
            "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
            "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
            "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
            "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
            "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p2.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"models_output_bucket\":\"sagemaker-us-east-1-485822383573\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"sagemaker-deeppurpose-2022-07-29-01-03-25-196\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train_sm\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p2.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_sm.py\"}\u001b[0m\n",
            "\u001b[34mSM_USER_ARGS=[\"--models_output_bucket\",\"sagemaker-us-east-1-485822383573\"]\u001b[0m\n",
            "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
            "\u001b[34mSM_HP_MODELS_OUTPUT_BUCKET=sagemaker-us-east-1-485822383573\u001b[0m\n",
            "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\u001b[0m\n",
            "\u001b[34mInvoking script with the following command:\u001b[0m\n",
            "\u001b[34m/usr/local/bin/python3.6 train_sm.py --models_output_bucket sagemaker-us-east-1-485822383573\u001b[0m\n",
            "\n",
            "2022-07-29 01:07:48 Training - Training image download completed. Training in progress.\u001b[34mWARNING:root:No normalization for BCUT2D_MWHI\u001b[0m\n",
            "\u001b[34mWARNING:root:No normalization for BCUT2D_MWLOW\u001b[0m\n",
            "\u001b[34mWARNING:root:No normalization for BCUT2D_CHGHI\u001b[0m\n",
            "\u001b[34mWARNING:root:No normalization for BCUT2D_CHGLO\u001b[0m\n",
            "\u001b[34mWARNING:root:No normalization for BCUT2D_LOGPHI\u001b[0m\n",
            "\u001b[34mWARNING:root:No normalization for BCUT2D_LOGPLOW\u001b[0m\n",
            "\u001b[34mWARNING:root:No normalization for BCUT2D_MRHI\u001b[0m\n",
            "\u001b[34mWARNING:root:No normalization for BCUT2D_MRLOW\u001b[0m\n",
            "\u001b[34mThe new directory is created!\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/298k [00:00<?, ?iB/s]#015100%|██████████| 298k/298k [00:00<00:00, 6.30MiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 4200 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 4200\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 6.12722. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , MSE: 1.49137 , Pearson Correlation: 0.38517 with p-value: 2.65E-16 , Concordance Index: 0.64362\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 1.35297. Total time 0.00027 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , MSE: 1.28656 , Pearson Correlation: 0.53319 with p-value: 3.17E-32 , Concordance Index: 0.68500\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 1.14054. Total time 0.00055 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , MSE: 0.87870 , Pearson Correlation: 0.63820 with p-value: 2.03E-49 , Concordance Index: 0.72825\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 0.52369. Total time 0.00083 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , MSE: 0.73761 , Pearson Correlation: 0.70430 with p-value: 3.48E-64 , Concordance Index: 0.75244\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 0.27246. Total time 0.00111 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , MSE: 0.66360 , Pearson Correlation: 0.73521 with p-value: 1.36E-72 , Concordance Index: 0.76486\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting MSE: 0.7705509926199963 , Pearson Correlation: 0.7038794926056084 with p-value: 1.29E-126 , Concordance Index: 0.7537463718371963\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['lipophilicity_astrazeneca_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/853k [00:00<?, ?iB/s]#015100%|██████████| 853k/853k [00:00<00:00, 19.3MiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 9982 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 9982\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:58] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:59] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:59] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:59] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:59] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:59] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:59] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:59] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:59] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:59] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:59] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:59] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:07:59] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 16.4336. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , MSE: 2.60863 , Pearson Correlation: 0.75430 with p-value: 3.21E-184 , Concordance Index: 0.77892\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 2.39266. Total time 0.00055 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , MSE: 1.78529 , Pearson Correlation: 0.82108 with p-value: 9.01E-245 , Concordance Index: 0.80957\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 1.53148. Total time 0.00138 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , MSE: 1.63581 , Pearson Correlation: 0.84003 with p-value: 9.33E-267 , Concordance Index: 0.82392\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 0.46347. Total time 0.00222 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , MSE: 1.55302 , Pearson Correlation: 0.84442 with p-value: 2.90E-272 , Concordance Index: 0.82547\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 0.40049. Total time 0.00277 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , MSE: 1.49559 , Pearson Correlation: 0.85108 with p-value: 5.99E-281 , Concordance Index: 0.82870\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting MSE: 1.8145057046453879 , Pearson Correlation: 0.8249210161769823 with p-value: 0.00E+00 , Concordance Index: 0.8211006662728504\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['solubility_aqsoldb_model', 'lipophilicity_astrazeneca_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/29.0k [00:00<?, ?iB/s]#015100%|██████████| 29.0k/29.0k [00:00<00:00, 584kiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 642 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 642\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 22.4817. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , MSE: 27.9686 , Pearson Correlation: 0.37025 with p-value: 2.60E-03 , Concordance Index: 0.62803\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 14.7446. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , MSE: 12.0224 , Pearson Correlation: 0.48819 with p-value: 4.27E-05 , Concordance Index: 0.67022\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 11.2547. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , MSE: 19.3088 , Pearson Correlation: 0.63966 with p-value: 1.27E-08 , Concordance Index: 0.72779\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 13.1641. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , MSE: 12.0812 , Pearson Correlation: 0.68124 with p-value: 5.82E-10 , Concordance Index: 0.75707\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 6.34780. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , MSE: 7.45666 , Pearson Correlation: 0.72065 with p-value: 1.89E-11 , Concordance Index: 0.77295\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting MSE: 12.271246059669906 , Pearson Correlation: 0.6335828701869923 with p-value: 1.01E-15 , Concordance Index: 0.7673273421149821\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['solubility_aqsoldb_model', 'hydrationfreeenergy_freesolv_model', 'lipophilicity_astrazeneca_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/82.5k [00:00<?, ?iB/s]#015100%|██████████| 82.5k/82.5k [00:00<00:00, 2.02MiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 910 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 906\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 26.9161. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , MSE: 1.90291 , Pearson Correlation: 0.28165 with p-value: 6.84E-03 , Concordance Index: 0.58506\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 1.72454. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , MSE: 8.06615 , Pearson Correlation: 0.35882 with p-value: 4.78E-04 , Concordance Index: 0.61277\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 7.26174. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , MSE: 6.40179 , Pearson Correlation: 0.47395 with p-value: 2.08E-06 , Concordance Index: 0.65052\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 5.70678. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , MSE: 2.03207 , Pearson Correlation: 0.53977 with p-value: 3.36E-08 , Concordance Index: 0.68215\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 2.38430. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , MSE: 0.43071 , Pearson Correlation: 0.60892 with p-value: 1.51E-10 , Concordance Index: 0.71206\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting MSE: 0.4860377827483014 , Pearson Correlation: 0.6863788496699608 with p-value: 1.09E-26 , Concordance Index: 0.7496351696461145\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['solubility_aqsoldb_model', 'caco2_wang_model', 'hydrationfreeenergy_freesolv_model', 'lipophilicity_astrazeneca_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/40.1k [00:00<?, ?iB/s]#015100%|██████████| 40.1k/40.1k [00:00<00:00, 1.08MiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 578 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 578\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 0.70057. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , AUROC: 0.62745 , AUPRC: 0.93303 , F1: 0.93577\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 0.33815. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , AUROC: 0.76750 , AUPRC: 0.96431 , F1: 0.93577\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 0.37174. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , AUROC: 0.81792 , AUPRC: 0.97213 , F1: 0.93577\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 0.30876. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , AUROC: 0.82072 , AUPRC: 0.97248 , F1: 0.93577\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 0.24320. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , AUROC: 0.83193 , AUPRC: 0.97342 , F1: 0.93577\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting AUROC: 0.8693069306930693 , AUPRC: 0.9729648046131207 , F1: 0.9308755760368664\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['solubility_aqsoldb_model', 'caco2_wang_model', 'hydrationfreeenergy_freesolv_model', 'hia_hou_model', 'lipophilicity_astrazeneca_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/126k [00:00<?, ?iB/s]#015100%|██████████| 126k/126k [00:00<00:00, 2.50MiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 1218 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 1212\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 0.69213. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , AUROC: 0.88138 , AUPRC: 0.92926 , F1: 0.74226\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 0.60576. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , AUROC: 0.83555 , AUPRC: 0.91819 , F1: 0.81481\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 0.36984. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , AUROC: 0.88 , AUPRC: 0.93573 , F1: 0.73684\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 0.34345. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , AUROC: 0.93194 , AUPRC: 0.96397 , F1: 0.85714\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 0.21639. Total time 0.00027 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , AUROC: 0.93888 , AUPRC: 0.96668 , F1: 0.86486\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting AUROC: 0.9245295698924731 , AUPRC: 0.9428173791979201 , F1: 0.8571428571428571\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['solubility_aqsoldb_model', 'caco2_wang_model', 'hydrationfreeenergy_freesolv_model', 'pgp_broccatelli_model', 'hia_hou_model', 'lipophilicity_astrazeneca_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/43.7k [00:00<?, ?iB/s]#015100%|██████████| 43.7k/43.7k [00:00<00:00, 868kiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 640 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 640\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 0.68444. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , AUROC: 0.52517 , AUPRC: 0.81895 , F1: 0.86725\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 0.54074. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , AUROC: 0.72925 , AUPRC: 0.91089 , F1: 0.86725\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 0.49142. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , AUROC: 0.74965 , AUPRC: 0.91528 , F1: 0.86725\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 0.51001. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , AUROC: 0.77551 , AUPRC: 0.92356 , F1: 0.86725\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 0.32889. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , AUROC: 0.78911 , AUPRC: 0.93238 , F1: 0.86725\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting AUROC: 0.6749571183533447 , AUPRC: 0.9053764726631484 , F1: 0.905982905982906\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['solubility_aqsoldb_model', 'caco2_wang_model', 'hydrationfreeenergy_freesolv_model', 'pgp_broccatelli_model', 'bioavailability_ma_model', 'hia_hou_model', 'lipophilicity_astrazeneca_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/89.9k [00:00<?, ?iB/s]#015100%|██████████| 89.9k/89.9k [00:00<00:00, 1.65MiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 1130 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 1111\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 196.117. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , MSE: 30.0583 , Pearson Correlation: 0.29998 with p-value: 1.25E-03 , Concordance Index: 0.56594\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 195.411. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , MSE: 20.2452 , Pearson Correlation: 0.43940 with p-value: 1.12E-06 , Concordance Index: 0.67729\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 51.5754. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , MSE: 19.9901 , Pearson Correlation: 0.40851 with p-value: 7.06E-06 , Concordance Index: 0.70243\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 13.8730. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , MSE: 26.7077 , Pearson Correlation: 0.26166 with p-value: 5.12E-03 , Concordance Index: 0.67841\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 29.0290. Total time 0.00027 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , MSE: 27.1334 , Pearson Correlation: 0.05527 with p-value: 5.61E-01 , Concordance Index: 0.62257\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting MSE: 55.59603504362214 , Pearson Correlation: 0.5224074094027839 with p-value: 3.17E-17 , Concordance Index: 0.6938827998259012\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['solubility_aqsoldb_model', 'caco2_wang_model', 'hydrationfreeenergy_freesolv_model', 'pgp_broccatelli_model', 'bioavailability_ma_model', 'vdss_lombardo_model', 'hia_hou_model', 'lipophilicity_astrazeneca_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/771k [00:00<?, ?iB/s]#015100%|██████████| 771k/771k [00:00<00:00, 15.5MiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 12665 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 12665\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 0.69230. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , AUROC: 0.85972 , AUPRC: 0.83560 , F1: 0.78892\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 0.36604. Total time 0.00083 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , AUROC: 0.85716 , AUPRC: 0.83137 , F1: 0.77968\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 0.32953. Total time 0.00166 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , AUROC: 0.84869 , AUPRC: 0.81526 , F1: 0.78215\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 0.18761. Total time 0.0025 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , AUROC: 0.84718 , AUPRC: 0.81702 , F1: 0.75589\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 0.07159. Total time 0.00361 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , AUROC: 0.83887 , AUPRC: 0.79886 , F1: 0.75715\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting AUROC: 0.8573541182179703 , AUPRC: 0.8052877859033992 , F1: 0.7703125000000001\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['solubility_aqsoldb_model', 'caco2_wang_model', 'hydrationfreeenergy_freesolv_model', 'pgp_broccatelli_model', 'bioavailability_ma_model', 'vdss_lombardo_model', 'hia_hou_model', 'cyp2c19_veith_model', 'lipophilicity_astrazeneca_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/800k [00:00<?, ?iB/s]#015100%|██████████| 800k/800k [00:00<00:00, 14.0MiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 13130 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 13130\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 0.67997. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , AUROC: 0.78002 , AUPRC: 0.52785 , F1: 0.44562\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 0.34171. Total time 0.00083 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , AUROC: 0.80188 , AUPRC: 0.55200 , F1: 0.50971\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 0.15913. Total time 0.00166 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , AUROC: 0.80259 , AUPRC: 0.55769 , F1: 0.48858\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 0.17250. Total time 0.00277 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , AUROC: 0.79424 , AUPRC: 0.55732 , F1: 0.45918\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 0.03417. Total time 0.00361 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , AUROC: 0.79773 , AUPRC: 0.56253 , F1: 0.51356\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting AUROC: 0.8380388760832341 , AUPRC: 0.6758124911386825 , F1: 0.594758064516129\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['solubility_aqsoldb_model', 'caco2_wang_model', 'hydrationfreeenergy_freesolv_model', 'pgp_broccatelli_model', 'bioavailability_ma_model', 'vdss_lombardo_model', 'hia_hou_model', 'cyp2c19_veith_model', 'lipophilicity_astrazeneca_model', 'cyp2d6_veith_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/746k [00:00<?, ?iB/s]#015100%|██████████| 746k/746k [00:00<00:00, 12.9MiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 12328 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 12328\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 0.69463. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , AUROC: 0.86875 , AUPRC: 0.83780 , F1: 0.73272\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 0.35752. Total time 0.00083 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , AUROC: 0.87716 , AUPRC: 0.85303 , F1: 0.75486\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 0.28132. Total time 0.00166 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , AUROC: 0.86703 , AUPRC: 0.84651 , F1: 0.73964\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 0.11111. Total time 0.0025 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , AUROC: 0.85613 , AUPRC: 0.83670 , F1: 0.72615\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 0.08722. Total time 0.00333 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , AUROC: 0.86946 , AUPRC: 0.84840 , F1: 0.74852\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting AUROC: 0.875971577337019 , AUPRC: 0.8427633350947343 , F1: 0.7558528428093646\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['solubility_aqsoldb_model', 'caco2_wang_model', 'hydrationfreeenergy_freesolv_model', 'cyp3a4_veith_model', 'pgp_broccatelli_model', 'bioavailability_ma_model', 'vdss_lombardo_model', 'hia_hou_model', 'cyp2c19_veith_model', 'lipophilicity_astrazeneca_model', 'cyp2d6_veith_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/760k [00:00<?, ?iB/s]#015100%|██████████| 760k/760k [00:00<00:00, 28.0MiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 12579 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 12579\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 0.69333. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , AUROC: 0.90352 , AUPRC: 0.89531 , F1: 0.81643\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 0.37231. Total time 0.00083 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , AUROC: 0.91338 , AUPRC: 0.90481 , F1: 0.82747\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 0.19919. Total time 0.00166 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , AUROC: 0.91735 , AUPRC: 0.91015 , F1: 0.81753\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 0.05916. Total time 0.0025 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , AUROC: 0.90985 , AUPRC: 0.89634 , F1: 0.82085\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 0.03049. Total time 0.00333 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , AUROC: 0.90187 , AUPRC: 0.89499 , F1: 0.80843\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting AUROC: 0.8897653963039224 , AUPRC: 0.8803851960995465 , F1: 0.7947826086956523\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['solubility_aqsoldb_model', 'caco2_wang_model', 'hydrationfreeenergy_freesolv_model', 'cyp3a4_veith_model', 'pgp_broccatelli_model', 'bioavailability_ma_model', 'vdss_lombardo_model', 'hia_hou_model', 'cyp2c19_veith_model', 'cyp1a2_veith_model', 'lipophilicity_astrazeneca_model', 'cyp2d6_veith_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/740k [00:00<?, ?iB/s]#015100%|██████████| 740k/740k [00:00<00:00, 11.0MiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 12092 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 12092\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 0.69849. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , AUROC: 0.85582 , AUPRC: 0.71731 , F1: 0.64756\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 0.36875. Total time 0.00083 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , AUROC: 0.87800 , AUPRC: 0.75994 , F1: 0.71219\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 0.24879. Total time 0.00166 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , AUROC: 0.87159 , AUPRC: 0.75504 , F1: 0.70321\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 0.13268. Total time 0.0025 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , AUROC: 0.86902 , AUPRC: 0.72847 , F1: 0.69028\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 0.08627. Total time 0.00333 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , AUROC: 0.86843 , AUPRC: 0.74519 , F1: 0.67315\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting AUROC: 0.8679629238996911 , AUPRC: 0.7608937020396782 , F1: 0.7012345679012346\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['solubility_aqsoldb_model', 'caco2_wang_model', 'hydrationfreeenergy_freesolv_model', 'cyp3a4_veith_model', 'pgp_broccatelli_model', 'bioavailability_ma_model', 'vdss_lombardo_model', 'hia_hou_model', 'cyp2c9_veith_model', 'cyp2c19_veith_model', 'cyp1a2_veith_model', 'lipophilicity_astrazeneca_model', 'cyp2d6_veith_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/45.6k [00:00<?, ?iB/s]#015100%|██████████| 45.6k/45.6k [00:00<00:00, 927kiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 669 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 666\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 0.67490. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , AUROC: 0.49487 , AUPRC: 0.24654 , F1: 0.0\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 0.50478. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , AUROC: 0.58076 , AUPRC: 0.27602 , F1: 0.0\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 0.50226. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , AUROC: 0.58846 , AUPRC: 0.27931 , F1: 0.0\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 0.34621. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , AUROC: 0.59743 , AUPRC: 0.28911 , F1: 0.0\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 0.30008. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , AUROC: 0.59615 , AUPRC: 0.31044 , F1: 0.0\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting AUROC: 0.6268605053651782 , AUPRC: 0.34881803279513146 , F1: 0.0\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['solubility_aqsoldb_model', 'caco2_wang_model', 'hydrationfreeenergy_freesolv_model', 'cyp3a4_veith_model', 'pgp_broccatelli_model', 'bioavailability_ma_model', 'vdss_lombardo_model', 'hia_hou_model', 'cyp2c9_substrate_carbonmangels_model', 'cyp2c9_veith_model', 'cyp2c19_veith_model', 'cyp1a2_veith_model', 'lipophilicity_astrazeneca_model', 'cyp2d6_veith_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/45.4k [00:00<?, ?iB/s]#015100%|██████████| 45.4k/45.4k [00:00<00:00, 1.12MiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 667 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 664\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 0.68283. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , AUROC: 0.65010 , AUPRC: 0.49387 , F1: 0.0\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 0.53462. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , AUROC: 0.75155 , AUPRC: 0.61676 , F1: 0.0\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 0.53452. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , AUROC: 0.77329 , AUPRC: 0.65379 , F1: 0.0\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 0.53801. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , AUROC: 0.77018 , AUPRC: 0.65608 , F1: 0.0\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 0.49285. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , AUROC: 0.78778 , AUPRC: 0.70094 , F1: 0.0\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting AUROC: 0.7958333333333333 , AUPRC: 0.7149842939519778 , F1: 0.0\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['solubility_aqsoldb_model', 'caco2_wang_model', 'hydrationfreeenergy_freesolv_model', 'cyp3a4_veith_model', 'pgp_broccatelli_model', 'bioavailability_ma_model', 'vdss_lombardo_model', 'hia_hou_model', 'cyp2c9_substrate_carbonmangels_model', 'cyp2c9_veith_model', 'cyp2c19_veith_model', 'cyp2d6_substrate_carbonmangels_model', 'cyp1a2_veith_model', 'lipophilicity_astrazeneca_model', 'cyp2d6_veith_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/46.0k [00:00<?, ?iB/s]#015100%|██████████| 46.0k/46.0k [00:00<00:00, 15.2MiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 670 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 667\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 0.69478. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , AUROC: 0.62544 , AUPRC: 0.58076 , F1: 0.63265\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 0.70634. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , AUROC: 0.63530 , AUPRC: 0.59744 , F1: 0.63265\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 0.66232. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , AUROC: 0.63620 , AUPRC: 0.61770 , F1: 0.63265\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 0.56129. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , AUROC: 0.63978 , AUPRC: 0.62937 , F1: 0.60215\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 0.46259. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , AUROC: 0.67383 , AUPRC: 0.65518 , F1: 0.66666\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting AUROC: 0.68048128342246 , AUPRC: 0.6313916392084714 , F1: 0.6666666666666667\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['solubility_aqsoldb_model', 'caco2_wang_model', 'hydrationfreeenergy_freesolv_model', 'cyp3a4_veith_model', 'pgp_broccatelli_model', 'bioavailability_ma_model', 'vdss_lombardo_model', 'hia_hou_model', 'cyp2c9_substrate_carbonmangels_model', 'cyp2c9_veith_model', 'cyp2c19_veith_model', 'cyp2d6_substrate_carbonmangels_model', 'cyp1a2_veith_model', 'lipophilicity_astrazeneca_model', 'cyp3a4_substrate_carbonmangels_model', 'cyp2d6_veith_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/138k [00:00<?, ?iB/s]#015100%|██████████| 138k/138k [00:00<00:00, 3.20MiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34min total: 2030 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 1975\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34m[01:10:28] WARNING: not removing hydrogen atom without neighbors\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 0.69179. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , AUROC: 0.87795 , AUPRC: 0.95671 , F1: 0.86592\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 0.44537. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , AUROC: 0.89475 , AUPRC: 0.96333 , F1: 0.86592\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 0.34820. Total time 0.00027 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , AUROC: 0.89744 , AUPRC: 0.96567 , F1: 0.91250\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 0.18204. Total time 0.00027 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , AUROC: 0.92096 , AUPRC: 0.97274 , F1: 0.91333\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 0.12622. Total time 0.00027 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , AUROC: 0.91438 , AUPRC: 0.96961 , F1: 0.91612\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting AUROC: 0.8585042569659442 , AUPRC: 0.9272337866333955 , F1: 0.8933333333333332\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['solubility_aqsoldb_model', 'caco2_wang_model', 'hydrationfreeenergy_freesolv_model', 'cyp3a4_veith_model', 'pgp_broccatelli_model', 'bioavailability_ma_model', 'vdss_lombardo_model', 'hia_hou_model', 'bbb_martins_model', 'cyp2c9_substrate_carbonmangels_model', 'cyp2c9_veith_model', 'cyp2c19_veith_model', 'cyp2d6_substrate_carbonmangels_model', 'cyp1a2_veith_model', 'lipophilicity_astrazeneca_model', 'cyp3a4_substrate_carbonmangels_model', 'cyp2d6_veith_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/214k [00:00<?, ?iB/s]#015100%|██████████| 214k/214k [00:00<00:00, 3.88MiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 2790 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 1797\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 7924.74. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , MSE: 2646.31 , Pearson Correlation: 0.28746 with p-value: 1.04E-06 , Concordance Index: 0.55805\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 2645.76. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , MSE: 467.452 , Pearson Correlation: 0.46732 with p-value: 1.53E-16 , Concordance Index: 0.63553\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 459.125. Total time 0.00027 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , MSE: 266.164 , Pearson Correlation: 0.59671 with p-value: 2.67E-28 , Concordance Index: 0.69371\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 324.790. Total time 0.00055 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , MSE: 247.625 , Pearson Correlation: 0.66801 with p-value: 2.01E-37 , Concordance Index: 0.72590\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 269.417. Total time 0.00055 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , MSE: 183.587 , Pearson Correlation: 0.70632 with p-value: 1.86E-43 , Concordance Index: 0.73348\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting MSE: 195.95532449151594 , Pearson Correlation: 0.5399003013063512 with p-value: 1.55E-43 , Concordance Index: 0.6782639885222381\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['solubility_aqsoldb_model', 'caco2_wang_model', 'hydrationfreeenergy_freesolv_model', 'cyp3a4_veith_model', 'pgp_broccatelli_model', 'bioavailability_ma_model', 'vdss_lombardo_model', 'hia_hou_model', 'ppbr_az_model', 'bbb_martins_model', 'cyp2c9_substrate_carbonmangels_model', 'cyp2c9_veith_model', 'cyp2c19_veith_model', 'cyp2d6_substrate_carbonmangels_model', 'cyp1a2_veith_model', 'lipophilicity_astrazeneca_model', 'cyp3a4_substrate_carbonmangels_model', 'cyp2d6_veith_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/53.6k [00:00<?, ?iB/s]#015100%|██████████| 53.6k/53.6k [00:00<00:00, 997kiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 667 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 665\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 6229.83. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , MSE: 558.788 , Pearson Correlation: 0.27683 with p-value: 2.33E-02 , Concordance Index: 0.47354\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 4279.68. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , MSE: 583.839 , Pearson Correlation: 0.28964 with p-value: 1.74E-02 , Concordance Index: 0.49498\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 8072.57. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , MSE: 436.577 , Pearson Correlation: 0.31782 with p-value: 8.77E-03 , Concordance Index: 0.56979\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 4500.90. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , MSE: 454.068 , Pearson Correlation: 0.24814 with p-value: 4.29E-02 , Concordance Index: 0.61906\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 11439.3. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , MSE: 768.546 , Pearson Correlation: 0.15649 with p-value: 2.06E-01 , Concordance Index: 0.61268\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting MSE: 15530.493538669469 , Pearson Correlation: 0.14796416776845286 with p-value: 8.92E-02 , Concordance Index: 0.6255179558011049\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['half_life_obach_model', 'solubility_aqsoldb_model', 'caco2_wang_model', 'hydrationfreeenergy_freesolv_model', 'cyp3a4_veith_model', 'pgp_broccatelli_model', 'bioavailability_ma_model', 'vdss_lombardo_model', 'hia_hou_model', 'ppbr_az_model', 'bbb_martins_model', 'cyp2c9_substrate_carbonmangels_model', 'cyp2c9_veith_model', 'cyp2c19_veith_model', 'cyp2d6_substrate_carbonmangels_model', 'cyp1a2_veith_model', 'lipophilicity_astrazeneca_model', 'cyp3a4_substrate_carbonmangels_model', 'cyp2d6_veith_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/91.6k [00:00<?, ?iB/s]#015100%|██████████| 91.6k/91.6k [00:00<00:00, 2.10MiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 1213 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 1020\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 4754.41. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , MSE: 3098.66 , Pearson Correlation: -0.1489 with p-value: 1.03E-01 , Concordance Index: 0.45157\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 3975.18. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , MSE: 2415.65 , Pearson Correlation: -0.0068 with p-value: 9.41E-01 , Concordance Index: 0.50627\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 3709.60. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , MSE: 2236.09 , Pearson Correlation: 0.20493 with p-value: 2.41E-02 , Concordance Index: 0.58430\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 2276.02. Total time 0.00027 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , MSE: 2104.27 , Pearson Correlation: 0.31972 with p-value: 3.51E-04 , Concordance Index: 0.63010\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 1551.25. Total time 0.00027 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , MSE: 2073.25 , Pearson Correlation: 0.38412 with p-value: 1.36E-05 , Concordance Index: 0.65490\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting MSE: 2044.992621053272 , Pearson Correlation: 0.43636095802402775 with p-value: 1.02E-12 , Concordance Index: 0.6569406506083934\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['half_life_obach_model', 'solubility_aqsoldb_model', 'caco2_wang_model', 'hydrationfreeenergy_freesolv_model', 'cyp3a4_veith_model', 'pgp_broccatelli_model', 'bioavailability_ma_model', 'clearance_hepatocyte_az_model', 'vdss_lombardo_model', 'hia_hou_model', 'ppbr_az_model', 'bbb_martins_model', 'cyp2c9_substrate_carbonmangels_model', 'cyp2c9_veith_model', 'cyp2c19_veith_model', 'cyp2d6_substrate_carbonmangels_model', 'cyp1a2_veith_model', 'lipophilicity_astrazeneca_model', 'cyp3a4_substrate_carbonmangels_model', 'cyp2d6_veith_model']\u001b[0m\n",
            "\u001b[34mDownloading...\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0.00/81.7k [00:00<?, ?iB/s]#015100%|██████████| 81.7k/81.7k [00:00<00:00, 16.2MiB/s]\u001b[0m\n",
            "\u001b[34mLoading...\u001b[0m\n",
            "\u001b[34mDone!\u001b[0m\n",
            "\u001b[34mDrug Property Prediction Mode...\u001b[0m\n",
            "\u001b[34min total: 1102 drugs\u001b[0m\n",
            "\u001b[34mencoding drug...\u001b[0m\n",
            "\u001b[34munique drugs: 1102\u001b[0m\n",
            "\u001b[34mDone.\u001b[0m\n",
            "\u001b[34mLet's use 1 GPU!\u001b[0m\n",
            "\u001b[34m--- Data Preparation ---\u001b[0m\n",
            "\u001b[34m--- Go for Training ---\u001b[0m\n",
            "\u001b[34mTraining at Epoch 1 iteration 0 with loss 2721.92. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 1 , MSE: 2273.78 , Pearson Correlation: 0.17601 with p-value: 6.59E-02 , Concordance Index: 0.58694\u001b[0m\n",
            "\u001b[34mTraining at Epoch 2 iteration 0 with loss 1916.86. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 2 , MSE: 1874.09 , Pearson Correlation: 0.35307 with p-value: 1.55E-04 , Concordance Index: 0.69976\u001b[0m\n",
            "\u001b[34mTraining at Epoch 3 iteration 0 with loss 1706.59. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 3 , MSE: 1908.02 , Pearson Correlation: 0.39070 with p-value: 2.44E-05 , Concordance Index: 0.73614\u001b[0m\n",
            "\u001b[34mTraining at Epoch 4 iteration 0 with loss 1818.95. Total time 0.0 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 4 , MSE: 1762.20 , Pearson Correlation: 0.39399 with p-value: 2.06E-05 , Concordance Index: 0.72609\u001b[0m\n",
            "\u001b[34mTraining at Epoch 5 iteration 0 with loss 1095.53. Total time 0.00027 hours\u001b[0m\n",
            "\u001b[34mValidation at Epoch 5 , MSE: 2136.04 , Pearson Correlation: 0.39870 with p-value: 1.60E-05 , Concordance Index: 0.72481\u001b[0m\n",
            "\u001b[34m--- Go for Testing ---\u001b[0m\n",
            "\u001b[34mTesting MSE: 1868.6182137012333 , Pearson Correlation: 0.539642966432716 with p-value: 5.03E-18 , Concordance Index: 0.7152602096132996\u001b[0m\n",
            "\u001b[34m--- Training Finished ---\u001b[0m\n",
            "\u001b[34m['half_life_obach_model', 'solubility_aqsoldb_model', 'caco2_wang_model', 'hydrationfreeenergy_freesolv_model', 'cyp3a4_veith_model', 'pgp_broccatelli_model', 'bioavailability_ma_model', 'clearance_hepatocyte_az_model', 'vdss_lombardo_model', 'hia_hou_model', 'ppbr_az_model', 'clearance_microsome_az_model', 'bbb_martins_model', 'cyp2c9_substrate_carbonmangels_model', 'cyp2c9_veith_model', 'cyp2c19_veith_model', 'cyp2d6_substrate_carbonmangels_model', 'cyp1a2_veith_model', 'lipophilicity_astrazeneca_model', 'cyp3a4_substrate_carbonmangels_model', 'cyp2d6_veith_model']\u001b[0m\n",
            "\u001b[34m['train_sm.py', 'result', 'data', 'models', 'train_local.py']\u001b[0m\n",
            "\u001b[34m2022-07-29 01:11:03,609 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
            "\n",
            "2022-07-29 01:11:29 Uploading - Uploading generated training model\n",
            "2022-07-29 01:11:29 Completed - Training job completed\n",
            "ProfilerReport-1659056605: NoIssuesFound\n",
            "Training seconds: 354\n",
            "Billable seconds: 354\n"
          ]
        }
      ],
      "source": [
        "estimator.fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5c7760c",
      "metadata": {
        "id": "c5c7760c"
      },
      "source": [
        "We now have trained all 21 models for ADME. Let's download the models locally and examine them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a731ed7",
      "metadata": {
        "id": "3a731ed7",
        "outputId": "b5895c80-fe6b-4185-e556-e2b849e4e3c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  models.zip\n",
            "   creating: models/bbb_martins_model/\n",
            "   creating: models/bioavailability_ma_model/\n",
            "   creating: models/caco2_wang_model/\n",
            "   creating: models/clearance_hepatocyte_az_model/\n",
            "   creating: models/clearance_microsome_az_model/\n",
            "   creating: models/cyp1a2_veith_model/\n",
            "   creating: models/cyp2c19_veith_model/\n",
            "   creating: models/cyp2c9_substrate_carbonmangels_model/\n",
            "   creating: models/cyp2c9_veith_model/\n",
            "   creating: models/cyp2d6_substrate_carbonmangels_model/\n",
            "   creating: models/cyp2d6_veith_model/\n",
            "   creating: models/cyp3a4_substrate_carbonmangels_model/\n",
            "   creating: models/cyp3a4_veith_model/\n",
            "   creating: models/half_life_obach_model/\n",
            "   creating: models/hia_hou_model/\n",
            "   creating: models/hydrationfreeenergy_freesolv_model/\n",
            "   creating: models/lipophilicity_astrazeneca_model/\n",
            "   creating: models/pgp_broccatelli_model/\n",
            "   creating: models/ppbr_az_model/\n",
            "   creating: models/solubility_aqsoldb_model/\n",
            "   creating: models/vdss_lombardo_model/\n",
            "  inflating: models/half_life_obach_model/model.pt  \n",
            "  inflating: models/half_life_obach_model/config.pkl  \n",
            "  inflating: models/solubility_aqsoldb_model/model.pt  \n",
            "  inflating: models/solubility_aqsoldb_model/config.pkl  \n",
            "  inflating: models/caco2_wang_model/model.pt  \n",
            "  inflating: models/caco2_wang_model/config.pkl  \n",
            "  inflating: models/hydrationfreeenergy_freesolv_model/model.pt  \n",
            "  inflating: models/hydrationfreeenergy_freesolv_model/config.pkl  \n",
            "  inflating: models/cyp3a4_veith_model/model.pt  \n",
            "  inflating: models/cyp3a4_veith_model/config.pkl  \n",
            "  inflating: models/pgp_broccatelli_model/model.pt  \n",
            "  inflating: models/pgp_broccatelli_model/config.pkl  \n",
            "  inflating: models/bioavailability_ma_model/model.pt  \n",
            "  inflating: models/bioavailability_ma_model/config.pkl  \n",
            "  inflating: models/clearance_hepatocyte_az_model/model.pt  \n",
            "  inflating: models/clearance_hepatocyte_az_model/config.pkl  \n",
            "  inflating: models/vdss_lombardo_model/model.pt  \n",
            "  inflating: models/vdss_lombardo_model/config.pkl  \n",
            "  inflating: models/hia_hou_model/model.pt  \n",
            "  inflating: models/hia_hou_model/config.pkl  \n",
            "  inflating: models/ppbr_az_model/model.pt  \n",
            "  inflating: models/ppbr_az_model/config.pkl  \n",
            "  inflating: models/clearance_microsome_az_model/model.pt  \n",
            "  inflating: models/clearance_microsome_az_model/config.pkl  \n",
            "  inflating: models/bbb_martins_model/model.pt  \n",
            "  inflating: models/bbb_martins_model/config.pkl  \n",
            "  inflating: models/cyp2c9_substrate_carbonmangels_model/model.pt  \n",
            "  inflating: models/cyp2c9_substrate_carbonmangels_model/config.pkl  \n",
            "  inflating: models/cyp2c9_veith_model/model.pt  \n",
            "  inflating: models/cyp2c9_veith_model/config.pkl  \n",
            "  inflating: models/cyp2c19_veith_model/model.pt  \n",
            "  inflating: models/cyp2c19_veith_model/config.pkl  \n",
            "  inflating: models/cyp2d6_substrate_carbonmangels_model/model.pt  \n",
            "  inflating: models/cyp2d6_substrate_carbonmangels_model/config.pkl  \n",
            "  inflating: models/cyp1a2_veith_model/model.pt  \n",
            "  inflating: models/cyp1a2_veith_model/config.pkl  \n",
            "  inflating: models/lipophilicity_astrazeneca_model/model.pt  \n",
            "  inflating: models/lipophilicity_astrazeneca_model/config.pkl  \n",
            "  inflating: models/cyp3a4_substrate_carbonmangels_model/model.pt  \n",
            "  inflating: models/cyp3a4_substrate_carbonmangels_model/config.pkl  \n",
            "  inflating: models/cyp2d6_veith_model/model.pt  \n",
            "  inflating: models/cyp2d6_veith_model/config.pkl  \n"
          ]
        }
      ],
      "source": [
        "s3 = boto3.client('s3')\n",
        "s3.download_file(bucket, 'ADME/models/models.zip', 'models.zip')\n",
        "!unzip models.zip -d models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4703bb8a",
      "metadata": {
        "id": "4703bb8a",
        "outputId": "5fd3ae64-e0c3-48d6-ffc1-b5fae05bced5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bbb_martins_model\t\t      cyp3a4_substrate_carbonmangels_model\r\n",
            "bioavailability_ma_model\t      cyp3a4_veith_model\r\n",
            "caco2_wang_model\t\t      half_life_obach_model\r\n",
            "clearance_hepatocyte_az_model\t      hia_hou_model\r\n",
            "clearance_microsome_az_model\t      hydrationfreeenergy_freesolv_model\r\n",
            "cyp1a2_veith_model\t\t      lipophilicity_astrazeneca_model\r\n",
            "cyp2c19_veith_model\t\t      pgp_broccatelli_model\r\n",
            "cyp2c9_substrate_carbonmangels_model  ppbr_az_model\r\n",
            "cyp2c9_veith_model\t\t      solubility_aqsoldb_model\r\n",
            "cyp2d6_substrate_carbonmangels_model  vdss_lombardo_model\r\n",
            "cyp2d6_veith_model\r\n"
          ]
        }
      ],
      "source": [
        "! ls models/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b814d660",
      "metadata": {
        "id": "b814d660"
      },
      "source": [
        "As you can see, we have downloaded the 21 models locally. You can now deploy these models entirely locally or on Sagemaker. \n",
        "\n",
        "This concludes our exercise. "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_python3",
      "language": "python",
      "name": "conda_python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "molecular_property_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}